{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78cb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b31c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File Loaded Successfully ---\n",
      "   cord_uid                                       sha source_x  \\\n",
      "0  vho70jcx  f056da9c64fbf00a4645ae326e8a4339d015d155  biorxiv   \n",
      "1  i9tbix2v  daf32e013d325a6feb80e83d15aabc64a48fae33  biorxiv   \n",
      "2  62gfisc6  f33c6d94b0efaa198f8f3f20e644625fa3fe10d2  biorxiv   \n",
      "3  058r9486  4da8a87e614373d56070ed272487451266dce919  biorxiv   \n",
      "4  wich35l7  eccef80cfbe078235df22398f195d5db462d8000  biorxiv   \n",
      "\n",
      "                                               title             doi pmcid  \\\n",
      "0  SIANN: Strain Identification by Alignment to N...  10.1101/001727   NaN   \n",
      "1  Spatial epidemiology of networked metapopulati...  10.1101/003889   NaN   \n",
      "2  Sequencing of the human IG light chain loci fr...  10.1101/006866   NaN   \n",
      "3  Bayesian mixture analysis for metagenomic comm...  10.1101/007476   NaN   \n",
      "4  Mapping a viral phylogeny onto outbreak trees ...  10.1101/010389   NaN   \n",
      "\n",
      "   pubmed_id  license                                           abstract  \\\n",
      "0        NaN  biorxiv  Next-generation sequencing is increasingly bei...   \n",
      "1        NaN  biorxiv  An emerging disease is one infectious epidemic...   \n",
      "2        NaN  biorxiv  Germline variation at immunoglobulin gene (IG)...   \n",
      "3        NaN  biorxiv  Deep sequencing of clinical samples is now an ...   \n",
      "4        NaN  biorxiv  Developing methods to reconstruct transmission...   \n",
      "\n",
      "  publish_time                                            authors journal  \\\n",
      "0   2014-01-10  Samuel Minot; Stephen D Turner; Krista L Ternu...     NaN   \n",
      "1   2014-06-04                                 Lin WANG; Xiang Li     NaN   \n",
      "2   2014-07-03  Corey T Watson; Karyn Meltz Steinberg; Tina A ...     NaN   \n",
      "3   2014-07-25                 Sofia Morfopoulou; Vincent Plagnol     NaN   \n",
      "4   2014-11-11                 Stephen P Velsko; Jonathan E Allen     NaN   \n",
      "\n",
      "   Microsoft Academic Paper ID WHO #Covidence  has_full_text   full_text_file  \\\n",
      "0                          NaN            NaN           True  biorxiv_medrxiv   \n",
      "1                          NaN            NaN           True  biorxiv_medrxiv   \n",
      "2                          NaN            NaN           True  biorxiv_medrxiv   \n",
      "3                          NaN            NaN           True  biorxiv_medrxiv   \n",
      "4                          NaN            NaN           True  biorxiv_medrxiv   \n",
      "\n",
      "                              url  \n",
      "0  https://doi.org/10.1101/001727  \n",
      "1  https://doi.org/10.1101/003889  \n",
      "2  https://doi.org/10.1101/006866  \n",
      "3  https://doi.org/10.1101/007476  \n",
      "4  https://doi.org/10.1101/010389  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45774 entries, 0 to 45773\n",
      "Data columns (total 17 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   cord_uid                     45774 non-null  object \n",
      " 1   sha                          31753 non-null  object \n",
      " 2   source_x                     45774 non-null  object \n",
      " 3   title                        45617 non-null  object \n",
      " 4   doi                          42440 non-null  object \n",
      " 5   pmcid                        26243 non-null  object \n",
      " 6   pubmed_id                    34641 non-null  float64\n",
      " 7   license                      45774 non-null  object \n",
      " 8   abstract                     37912 non-null  object \n",
      " 9   publish_time                 45765 non-null  object \n",
      " 10  authors                      43774 non-null  object \n",
      " 11  journal                      41707 non-null  object \n",
      " 12  Microsoft Academic Paper ID  964 non-null    float64\n",
      " 13  WHO #Covidence               1768 non-null   object \n",
      " 14  has_full_text                45774 non-null  bool   \n",
      " 15  full_text_file               35558 non-null  object \n",
      " 16  url                          45472 non-null  object \n",
      "dtypes: bool(1), float64(2), object(14)\n",
      "memory usage: 5.6+ MB\n",
      "None\n",
      "(45774, 17)\n",
      "cord_uid                        object\n",
      "sha                             object\n",
      "source_x                        object\n",
      "title                           object\n",
      "doi                             object\n",
      "pmcid                           object\n",
      "pubmed_id                      float64\n",
      "license                         object\n",
      "abstract                        object\n",
      "publish_time                    object\n",
      "authors                         object\n",
      "journal                         object\n",
      "Microsoft Academic Paper ID    float64\n",
      "WHO #Covidence                  object\n",
      "has_full_text                     bool\n",
      "full_text_file                  object\n",
      "url                             object\n",
      "dtype: object\n",
      "cord_uid                           0\n",
      "sha                            14021\n",
      "source_x                           0\n",
      "title                            157\n",
      "doi                             3334\n",
      "pmcid                          19531\n",
      "pubmed_id                      11133\n",
      "license                            0\n",
      "abstract                        7862\n",
      "publish_time                       9\n",
      "authors                         2000\n",
      "journal                         4067\n",
      "Microsoft Academic Paper ID    44810\n",
      "WHO #Covidence                 44006\n",
      "has_full_text                      0\n",
      "full_text_file                 10216\n",
      "url                              302\n",
      "dtype: int64\n",
      "\n",
      "--- Dropped columns: WHO #Covidence, Microsoft Academic Paper ID, sha, full_text_file, url ---\n",
      "--- Filled missing values in abstract, authors, journal, and license ---\n",
      "--- Removed 157 rows with a missing title ---\n",
      "\n",
      "Missing values percentage after cleaning:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3698452545.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['abstract'].fillna('No abstract available', inplace=True)\n",
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3698452545.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['authors'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3698452545.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['journal'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3698452545.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['license'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cord_uid          0.000000\n",
      "source_x          0.000000\n",
      "title             0.000000\n",
      "doi               7.297718\n",
      "pmcid            42.481969\n",
      "pubmed_id        24.061205\n",
      "license           0.000000\n",
      "abstract          0.000000\n",
      "publish_time      0.019729\n",
      "authors           0.000000\n",
      "journal           0.000000\n",
      "has_full_text     0.000000\n",
      "dtype: float64\n",
      "\n",
      "--- Cleaning complete! ---\n",
      "Cleaned dataset saved to: cleaned_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Prepare the Data ---\n",
    "#load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"metadata.csv\")\n",
    "    print(\"--- File Loaded Successfully ---\")\n",
    "\n",
    "    #display first few rows\n",
    "    print(df.head())\n",
    "\n",
    "    #summary of the dataset\n",
    "    print(df.info())\n",
    "\n",
    "    #rows and columns\n",
    "    print(df.shape)\n",
    "\n",
    "    #identify data types\n",
    "    print(df.dtypes)\n",
    "\n",
    "    #statistical summary\n",
    "    df.describe()\n",
    "\n",
    "    #missing values\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "    \n",
    "#HANDLE MISSING DATA\n",
    "# Define columns to remove\n",
    "columns_to_drop = [\n",
    "    'WHO #Covidence',\n",
    "    'Microsoft Academic Paper ID',\n",
    "    'sha',\n",
    "    'full_text_file',\n",
    "    'url'\n",
    "]\n",
    "\n",
    "# Drop the specified columns from the DataFrame\n",
    "df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\n--- Dropped columns: {', '.join(columns_to_drop)} ---\")\n",
    "\n",
    "\n",
    "#fill missing values\n",
    "# Fill missing 'abstract' with a placeholder\n",
    "df_cleaned['abstract'].fillna('No abstract available', inplace=True)\n",
    "\n",
    "# Fill 'authors', 'journal', and 'license' with 'Unknown'\n",
    "df_cleaned['authors'].fillna('Unknown', inplace=True)\n",
    "df_cleaned['journal'].fillna('Unknown', inplace=True)\n",
    "df_cleaned['license'].fillna('Unknown', inplace=True)\n",
    "\n",
    "print(\"--- Filled missing values in abstract, authors, journal, and license ---\")\n",
    "\n",
    "#drop rows with mising title\n",
    "# Get the row count before dropping\n",
    "rows_before = len(df_cleaned)\n",
    "\n",
    "# Drop rows where the 'title' is missing\n",
    "df_cleaned.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "rows_after = len(df_cleaned)\n",
    "print(f\"--- Removed {rows_before - rows_after} rows with a missing title ---\")\n",
    "\n",
    "# Verify that there are no more missing values in the key columns\n",
    "print(\"\\nMissing values percentage after cleaning:\")\n",
    "print(df_cleaned.isnull().sum() / len(df_cleaned) * 100)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "cleaned_file_path = 'cleaned_metadata.csv'\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"\\n--- Cleaning complete! ---\")\n",
    "print(f\"Cleaned dataset saved to: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87de77d",
   "metadata": {},
   "source": [
    "# CORD-19 Research Paper Analysis 🔬\n",
    "\n",
    "## 1. Data Loading and Preparation\n",
    "\n",
    "### Objective\n",
    "The first step is to load the `metadata.csv` dataset and perform initial cleaning. The goal of this phase is to prepare the data for exploratory analysis by handling missing values and formatting key columns.\n",
    "\n",
    "### Actions Taken\n",
    "The following cleaning and preparation steps were performed:\n",
    "\n",
    "* **Load Data**: The dataset was loaded into a pandas DataFrame.\n",
    "* **Drop Unnecessary Columns**: Columns with a high percentage of missing values (`WHO #Covidence`, `Microsoft Academic Paper ID`) or those not needed for this analysis (`sha`, `url`) were removed.\n",
    "* **Handle Missing Values**:\n",
    "    * Missing `journal` and `authors` were filled with the placeholder \"Unknown\".\n",
    "    * Missing `abstract` text was filled with \"No abstract available\".\n",
    "* **Format Dates**: The `publish_time` column was converted to a proper datetime format, and a new `publish_year` column was created to make time-based analysis easier.\n",
    "* **Remove Invalid Rows**: Any rows with a missing `title` or an invalid `publish_time` were dropped to ensure data quality.\n",
    "\n",
    "### Outcome\n",
    "After these steps, the dataset is cleaned and contains the necessary columns for analysis. We can now proceed to the Exploratory Data Analysis (EDA) phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ded5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File Loaded Successfully ---\n",
      "\n",
      "--- Data Preparation Complete (created 'publish_year' column) ---\n",
      "\n",
      "--- Publications per Year ---\n",
      "publish_year\n",
      "1951       1\n",
      "1952       1\n",
      "1955       1\n",
      "1957       1\n",
      "1959       1\n",
      "        ... \n",
      "2016    2965\n",
      "2017    2911\n",
      "2018    3094\n",
      "2019    3144\n",
      "2020    2953\n",
      "Name: count, Length: 65, dtype: int64\n",
      "-----------------------------------\n",
      "\n",
      "--- Top 10 Journals Publishing Research ---\n",
      "journal\n",
      "Journal of Virology        1740\n",
      "PLoS One                   1567\n",
      "Virology                    864\n",
      "Emerg Infect Dis            745\n",
      "The Lancet                  596\n",
      "Viruses                     565\n",
      "Virus Research              495\n",
      "Sci Rep                     491\n",
      "Vaccine                     483\n",
      "Veterinary Microbiology     443\n",
      "Name: count, dtype: int64\n",
      "-----------------------------------\n",
      "\n",
      "--- Top 20 Most Frequent Words in Titles ---\n",
      "[('virus', 8018), ('respiratory', 4897), ('coronavirus', 4590), ('infection', 3533), ('viral', 2892), ('human', 2756), ('protein', 2717), ('influenza', 2551), ('disease', 2467), ('sars', 2319), ('syndrome', 2297), ('acute', 2090), ('infectious', 2032), ('cell', 1833), ('health', 1829), ('viruses', 1789), ('infections', 1772), ('cells', 1734), ('detection', 1666), ('rna', 1660)]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#prepare and perform basic data analysis\n",
    "try:\n",
    "    df = pd.read_csv(\"cleaned_metadata.csv\")\n",
    "    print(\"--- File Loaded Successfully ---\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# --- PREPARE THE DATA ---\n",
    "# Convert 'publish_time' to datetime format\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')\n",
    "\n",
    "# Create 'publish_year' by extracting the year\n",
    "# We drop any rows where the date was invalid to prevent errors\n",
    "df.dropna(subset=['publish_time'], inplace=True)\n",
    "df['publish_year'] = df['publish_time'].dt.year.astype(int)\n",
    "print(\"--- Data Preparation Complete (created 'publish_year' column) ---\\n\")\n",
    "\n",
    "\n",
    "# ---PERFORM BASIC DATA ANALYSIS ---\n",
    "\n",
    "# --- Count Papers by Publication Year ---\n",
    "print(\"--- Publications per Year ---\")\n",
    "papers_per_year = df['publish_year'].value_counts().sort_index()\n",
    "print(papers_per_year)\n",
    "print(\"-\" * 35)\n",
    "\n",
    "\n",
    "# --- Identify Top Journals ---\n",
    "print(\"\\n--- Top 10 Journals Publishing Research ---\")\n",
    "# Exclude the 'Unknown' category from the count\n",
    "top_journals = df[df['journal'] != 'Unknown']['journal'].value_counts().head(10)\n",
    "print(top_journals)\n",
    "print(\"-\" * 35)\n",
    "\n",
    "\n",
    "# ---Find Most Frequent Words in Titles ---\n",
    "print(\"\\n--- Top 20 Most Frequent Words in Titles ---\")\n",
    "# Define a simple list of common English \"stop words\"\n",
    "stop_words = set([\n",
    "    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'http', 'https', 'et', 'al', 'author', 'figure',\n",
    "    'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'of', 'at', 'by', 'for', 'with', 'about',\n",
    "    'to', 'in', 'on', 'is', 'are', 'was', 'were', 'it', 'that', 'which', 'who', 'what', 'when', 'where',\n",
    "    'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "    'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now',\n",
    "    'from', '-PRON-', 'using', 'study', 'we', 'our', 'results', 'data', 'analysis', 'based'\n",
    "])\n",
    "# Combine all titles into one large text block\n",
    "all_titles = ' '.join(df['title'].astype(str).tolist())\n",
    "# Find all words, convert to lowercase, and filter out stop words\n",
    "words = [word for word in re.findall(r'\\b\\w+\\b', all_titles.lower()) if word not in stop_words and len(word) > 2]\n",
    "# Count the frequency of the remaining words\n",
    "word_counts = Counter(words)\n",
    "# Print the 20 most common words\n",
    "print(word_counts.most_common(20))\n",
    "print(\"-\" * 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2dcba0",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Analysis\n",
    "\n",
    "### Objective\n",
    "This section prepares the loaded `cleaned_metadata.csv` file for analysis and then performs three basic analyses: counting publications per year, identifying the top journals, and finding the most frequent words in paper titles.\n",
    "\n",
    "### Part A: Data Preparation\n",
    "The following preparation steps are performed on the DataFrame:\n",
    "* The `publish_time` column is converted to a proper datetime format.\n",
    "* A `publish_year` column is created by extracting the year from `publish_time` to enable time-based analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### Part B: Basic Data Analysis\n",
    "The script then performs and prints the results for the following three analyses:\n",
    "\n",
    "* **Publications per Year:** Counts the total number of papers for each year.\n",
    "* **Top 10 Journals:** Identifies the 10 journals with the highest number of publications.\n",
    "* **Top 20 Words in Titles:** Extracts and counts the most common words found in paper titles after removing common stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d156eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated: publications_over_time.png ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3169379734.py:20: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=top_journals.values, y=top_journals.index, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generated: top_journals.png ---\n",
      "--- Generated: titles_wordcloud.png ---\n",
      "--- Generated: papers_by_source.png ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xtreme\\AppData\\Local\\Temp\\ipykernel_15732\\3169379734.py:55: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=source_counts.index, y=source_counts.values, palette='crest')\n"
     ]
    }
   ],
   "source": [
    "#VISUALIZE THE DATA\n",
    "# ---  Plot 1: Number of Publications Over Time ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "papers_per_year = df['publish_year'].value_counts().sort_index()\n",
    "# Filter for a reasonable year range\n",
    "\n",
    "#papers_per_year = papers_per_year.loc[2015:2021]\n",
    "sns.lineplot(x=papers_per_year.index, y=papers_per_year.values, marker='o')\n",
    "plt.title('Number of Publications Over Time', fontsize=16)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Papers')\n",
    "plt.grid(True)\n",
    "plt.savefig('publications_over_time.png')\n",
    "plt.close()\n",
    "print(\"--- Generated: publications_over_time.png ---\")\n",
    "\n",
    "\n",
    "# ---  Plot 2: Top Publishing Journals ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_journals = df[df['journal'] != 'Unknown']['journal'].value_counts().head(10)\n",
    "sns.barplot(x=top_journals.values, y=top_journals.index, palette='viridis')\n",
    "plt.title('Top 10 Publishing Journals', fontsize=16)\n",
    "plt.xlabel('Number of Papers')\n",
    "plt.ylabel('Journal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_journals.png')\n",
    "plt.close()\n",
    "print(\"--- Generated: top_journals.png ---\")\n",
    "\n",
    "\n",
    "# ---  Plot 3: Word Cloud of Titles ---\n",
    "# Add domain-specific stop words\n",
    "custom_stop_words = set(STOPWORDS) | set(['preprint', 'doi', 'copyright', 'peer', 'reviewed', 'author'])\n",
    "# Combine all titles into a single string\n",
    "all_titles = ' '.join(df['title'].astype(str).tolist())\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=custom_stop_words,\n",
    "    colormap='plasma'\n",
    ").generate(all_titles)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Paper Titles', fontsize=16)\n",
    "plt.savefig('titles_wordcloud.png')\n",
    "plt.close()\n",
    "print(\"--- Generated: titles_wordcloud.png ---\")\n",
    "\n",
    "\n",
    "# ---  Plot 4: Distribution by Source ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "source_counts = df['source_x'].value_counts()\n",
    "sns.barplot(x=source_counts.index, y=source_counts.values, palette='crest')\n",
    "plt.title('Distribution of Papers by Source', fontsize=16)\n",
    "plt.xlabel('Source')\n",
    "plt.ylabel('Number of Papers')\n",
    "plt.savefig('papers_by_source.png')\n",
    "plt.close()\n",
    "print(\"--- Generated: papers_by_source.png ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c581def",
   "metadata": {},
   "source": [
    "# Data Visualization of Publication Dataset\n",
    "\n",
    "This report provides an overview of publication patterns, top journals, common research themes, and source distribution.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Number of Publications Over Time  \n",
    "**File:** `publications_over_time.png`\n",
    "\n",
    "This plot displays the **trend in publications over the years**.  \n",
    "Key observations:\n",
    "- Identifies peaks and drops in research activity.\n",
    "- Helps correlate trends with global events or advancements in the field.\n",
    "- A steady increase suggests growing interest and research output.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Top Publishing Journals  \n",
    "**File:**top_journals.png`\n",
    "\n",
    "This chart highlights the **top 10 journals** by the number of papers published.  \n",
    "Key observations:\n",
    "- Reveals the most influential journals in the field.\n",
    "- Useful for researchers when selecting publication venues.\n",
    "- Indicates where the majority of studies are being disseminated.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Word Cloud of Paper Titles  \n",
    "**File:** `titles_wordcloud.png`\n",
    "\n",
    "The word cloud illustrates the **most frequently occurring keywords in paper titles**.  \n",
    "Key observations:\n",
    "- Larger words indicate higher frequency.\n",
    "- Offers insight into **dominant research themes and focus areas**.\n",
    "- Helps identify emerging topics or commonly discussed concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Distribution by Source  \n",
    "**File:** `papers_by_source.png`\n",
    "\n",
    "This bar chart shows the **distribution of papers across different sources**.  \n",
    "Key observations:\n",
    "- Highlights which data sources contribute the most publications.\n",
    "- Useful for understanding data diversity and coverage.\n",
    "- Helps prioritize sources for future research or data collection.\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Insights\n",
    "- Research output has **grown over time**, indicating increasing interest in the domain.  \n",
    "- A few journals dominate publication activity, making them key venues for researchers.  \n",
    "- The most common keywords reflect **core themes and emerging trends** in the field.  \n",
    "- Data sources vary widely, but a handful contribute **most of the available research papers**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
